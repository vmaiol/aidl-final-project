{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1dad3a-765e-429b-a094-4117f599224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from pyproj import Proj\n",
    "from dask.diagnostics import ProgressBar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xesmf as xe\n",
    "import rioxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e7aa4c-37d9-4089-8ea8-b1cf3c346a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '0.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab852d-6f58-4a13-bf34-c2ea133e3c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_point_0025_grid(latitude, longitude):\n",
    "    lat_grid = np.arange(0, 90, 0.025)\n",
    "    lon_grid = np.arange(-180, -40, 0.025)\n",
    "\n",
    "    diff = np.abs(lat_grid - latitude)\n",
    "    lat_point_grid = lat_grid[np.where((diff) == np.min(diff))]\n",
    "    diff = np.abs(lon_grid - longitude)\n",
    "    lon_point_grid = lon_grid[np.where((diff) == np.min(diff))]\n",
    "    \n",
    "    return lat_point_grid, lon_point_grid\n",
    "\n",
    "def open_elevation_data():\n",
    "    data = rioxarray.open_rasterio('/data/AIDL-UPC/wc2.1_30s_elev.tif')\n",
    "    data = data.rename({'x': 'lon','y': 'lat'})\n",
    "    data = data.assign_coords(lat=-data.lat)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d91b4-165c-4a55-8faf-adacb0584f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select lat y lons from the points of interest\n",
    "\n",
    "file = '/data/AIDL-UPC/daymet_v4_daily/prcp/used/short/daymet_v4_daily_na_prcp_sel200_latlon_nonan.nc'\n",
    "data_latlon = xr.open_dataset(file)\n",
    "\n",
    "# read mean and std to normalize the input data\n",
    "file = '/data/AIDL-UPC/std_mean_variables_ERA5_v'+version+'.nc'\n",
    "data_mean_std = xr.open_dataset(file)\n",
    "mean = data_mean_std.mean_all\n",
    "std = data_mean_std.std_all\n",
    "\n",
    "# read elevation file and land-ocean mask\n",
    "land_ocean= xr.open_dataset('/data/AIDL-UPC/land_ocean_mask_v'+version+'.nc')\n",
    "\n",
    "elevation_norm= xr.open_dataset('/data/AIDL-UPC/elevation_norm_v'+version+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc875ae-c43e-4d66-83b0-ed964e723747",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/vestella/data/NAS-data/terolink/archive/reanalysis/unversioned/era5/'\n",
    "\n",
    "path_precip  = '/data/AIDL-UPC/daymet_v4_daily/prcp/used/short/'\n",
    "file_precip = 'daymet_v4_daily_na_prcp_'\n",
    "\n",
    "# define number of points to be computed from a random selection of the non-nan points\n",
    "npoints = 1\n",
    "rng = np.random.default_rng()\n",
    "points = rng.integers(low=0, high=13570, size=npoints)\n",
    "\n",
    "\n",
    "#latitudes = data_latlon.lat.values[:npoints]\n",
    "#longitudes = data_latlon.lon.values[:npoints]\n",
    "\n",
    "\n",
    "for iyear in range(2000, 2001):\n",
    "    #with ProgressBar():\n",
    "    data_precip = xr.open_dataset(path_precip + file_precip+str(iyear) + '_sel200.nc')\n",
    "    ipoint_counter = 1\n",
    "    for ipoint in points:\n",
    "        \n",
    "        if ipoint<10:\n",
    "            label_ipoint = '0'+str(ipoint)\n",
    "        else:\n",
    "            label_ipoint = str(ipoint)\n",
    "        \n",
    "        latitude, longitude = find_closest_point_0025_grid(data_latlon.lat.values[ipoint], data_latlon.lon.values[ipoint])\n",
    "        \n",
    "        # create the grid of the map surrounding the point of interest\n",
    "        lats = np.round(np.arange(latitude-2.5, latitude+2.52, 0.025),3)\n",
    "        lons = np.round(np.arange(longitude-2.5, longitude+2.52, 0.025),3)\n",
    "\n",
    "        ds_out = xr.Dataset(\n",
    "            {\n",
    "                \"lat\": ([\"lat\"], lats),\n",
    "                \"lon\": ([\"lon\"], lons),\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # create regrider from the low resolution (25km) to the high resolution (2.5km)\n",
    "        data_era5_0 = xr.open_zarr(path + vars_name[0]+'_day/'+vars_name[0] + '_'  +str(iyear) +  '.zarr')\n",
    "        data_era5_0 = data_era5_0.isel(lat = np.arange(720)).load()\n",
    "        regridder = xe.Regridder(data_era5_0, ds_out, 'nearest_s2d')\n",
    "        dr_out = regridder(data_era5_0)[vars_name[0]].values\n",
    "\n",
    "\n",
    "        # add elevation to the list of variables\n",
    "        \n",
    "        additional = ['elevation', 'land_mask']\n",
    "        vars_name_tot = vars_name + additional\n",
    "        \n",
    "        # define the output array shape\n",
    "        if ipoint_counter == 1:\n",
    "            out = np.empty((len(vars_name_tot),dr_out.shape[0],dr_out.shape[1], dr_out.shape[2]), dtype = np.float32)\n",
    "        \n",
    "        # for each variable\n",
    "        for ivar in range(len(vars_name_tot)):#len(vars_name)\n",
    "            if vars_name_tot[ivar] not in additional:\n",
    "                # read era5 data\n",
    "                data_era5 = xr.open_zarr(path + vars_name[ivar]+'_day/'+vars_name[ivar] + '_'  +str(iyear) +  '.zarr')\n",
    "                if data_era5.lat.shape[0]!= data_era5_0.lat.shape[0]:\n",
    "                    data_era5 = data_era5.isel(lat = np.arange(720)).load()\n",
    "                else:\n",
    "                    data_era5 = data_era5.load()\n",
    "                # regrid the data    \n",
    "                regrided = regridder(data_era5)[vars_name[ivar]].values[np.newaxis,np.newaxis,:,:,:]\n",
    "                # normalize the data\n",
    "                regrided = (regrided- mean.sel(variable = vars_name[ivar]).values)/std.sel(variable = vars_name[ivar]).values\n",
    "            \n",
    "            elif vars_name_tot[ivar] == 'elevation' : \n",
    "                # select smaller region\n",
    "                c_elev = elevation_norm.sel(lat = slice(*[ds_out.lat[0]-1, ds_out.lat[-1]+1]), \n",
    "                                            lon = slice(*[ds_out.lon[0]-1, ds_out.lon[-1]+1]))\n",
    "                # regrid the data\n",
    "                regridder_other = xe.Regridder(c_elev, ds_out, 'bilinear')\n",
    "                regrided = regridder_other(c_elev)\n",
    "                regrided = regrided[list(regrided.keys())[0]].values[np.newaxis,np.newaxis,:,:,:]\n",
    "            \n",
    "            elif vars_name_tot[ivar] == 'land_mask': \n",
    "                # select smaller region\n",
    "                c_land = land_ocean.sel(lat = slice(*[ds_out.lat[0]-1, ds_out.lat[-1]+1]), \n",
    "                                            lon = slice(*[ds_out.lon[0]-1, ds_out.lon[-1]+1]))\n",
    "                # regrid the data\n",
    "                regridder_other = xe.Regridder(c_land, ds_out, 'nearest_s2d')\n",
    "                regrided = regridder_other(c_land)\n",
    "                regrided = regrided[list(regrided.keys())[0]].values[np.newaxis,np.newaxis,:,:,:]\n",
    "\n",
    "            # store the regridded data in the defined array\n",
    "            out[ivar, :,:,:] = regrided\n",
    "            \n",
    "        #select the precipitation value of the target location\n",
    "        c = np.argwhere((data_precip.lon.values == data_latlon.lon.values[ipoint]))\n",
    "        if c.shape[0]>1:\n",
    "            c= c[0]\n",
    "        y,x  = c[0]\n",
    "        \n",
    "        precip = data_precip.isel(x = x, y =y).prcp.values\n",
    "        \n",
    "        # for each day of the year \n",
    "        for iday in range(365):#o\n",
    "            \n",
    "            if iday<9:\n",
    "                day_label = '00' + str(iday+1)\n",
    "            elif iday<99:\n",
    "                day_label = '0' + str(iday+1)\n",
    "            else:\n",
    "                day_label =  str(iday+1)\n",
    "            # create the Xarray dataset with variables and coordinates\n",
    "            da = xr.Dataset(\n",
    "                    data_vars=dict(\n",
    "                                input = ([\"variable\", \"lat\", \"lon\"], out[:,iday,:,:]),\n",
    "                                target = precip[iday],\n",
    "                                ),\n",
    "                    coords=dict(\n",
    "                                lon=([\"lon\"], lons),\n",
    "                                lat=([\"lat\"], lats),\n",
    "                                time=data_era5.time.values[iday],\n",
    "                                variable=vars_name_tot,\n",
    "                                points = 'loc'+str(ipoint_counter),\n",
    "                                lon_point = longitude,\n",
    "                                lat_point = latitude,\n",
    "                            ),\n",
    "                    #attrs=dict(description=\"Low_res_Data\",),\n",
    "                    )\n",
    "            # save it \n",
    "            da.to_netcdf('/data/AIDL-UPC/final_data/v'+version+'/location'+str(ipoint_counter)+'_year'+str(iyear)+'_day'+day_label+'_v'+version+'.nc')\n",
    "        ipoint_counter +=1\n",
    "    print('/data/AIDL-UPC/final_data/v'+version+'/location'+str(ipoint_counter)+'_year'+str(iyear)+'_day'+day_label+'_v'+version+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2285ef7b-9867-4510-8ea0-b2bd50a181e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
